{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Maze Navigation: NEAT vs DQN Training Comparison\n",
    "\n",
    "This notebook provides a complete workflow for training, evaluating, and comparing both NEAT and DQN approaches for maze navigation.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup and Imports  \n",
    "2. Environment Exploration  \n",
    "3. Train NEAT Agent  \n",
    "4. Train DQN Agent  \n",
    "5. Compare Performance  \n",
    "6. Visualize Decision Making  \n",
    "7. Robustness Testing  \n",
    "8. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 1: Setup and Imports\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom imports\n",
    "from env.maze_env import MazeEnv\n",
    "from neuroevolution.neat_solver import NEATMazeSolver, create_neat_config\n",
    "from reinforcement_learning.dqn_solver import DQNMazeSolver\n",
    "from analysis.visualize_training import TrainingVisualizer\n",
    "from analysis.robustness_tests import RobustnessTestSuite\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ… All imports successful!\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Exploration\n",
    "\n",
    "Let's explore the maze environment and understand its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 2: Environment Exploration\n",
    "# ============================================================================\n",
    "\n",
    "env = MazeEnv()\n",
    "\n",
    "print(\"Maze Configuration:\")\n",
    "print(f\"  Size: {env.height}x{env.width}\")\n",
    "print(f\"  Start: {env.start_pos}\")\n",
    "print(f\"  Goal: {env.goal_pos}\")\n",
    "print(f\"  Observation Space: {env.observation_space}\")\n",
    "print(f\"  Action Space: {env.action_space}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "env.reset()\n",
    "env._draw_maze(ax)\n",
    "ax.set_title(\"Initial Maze Configuration\", fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTesting random agent for 100 steps...\")\n",
    "obs, _ = env.reset()\n",
    "total_reward = 0\n",
    "for step in range(100):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"Random agent performance:\")\n",
    "print(f\"  Steps taken: {step + 1}\")\n",
    "print(f\"  Total reward: {total_reward:.2f}\")\n",
    "print(f\"  Final distance: {info['distance_to_goal']:.2f}\")\n",
    "print(f\"  Cells explored: {info['unique_cells_visited']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train NEAT Agent\n",
    "\n",
    "Training the Neuroevolution approach using the NEAT algorithm."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 3: Train NEAT Agent\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING NEAT AGENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "config_path = create_neat_config('../neuroevolution/config-neat.txt')\n",
    "neat_solver = NEATMazeSolver(config_path, log_dir='../logs/neat')\n",
    "\n",
    "print(\"\\nStarting NEAT training...\")\n",
    "print(\"This will take approximately 20-30 minutes on CPU\\n\")\n",
    "\n",
    "winner = neat_solver.train(generations=50)\n",
    "\n",
    "print(\"\\nâœ… NEAT training complete!\")\n",
    "print(f\"Best fitness: {neat_solver.best_fitness:.2f}\")\n",
    "\n",
    "neat_solver.visualize_training()\n",
    "\n",
    "print(\"\\nEvaluating best NEAT genome...\")\n",
    "neat_results = neat_solver.evaluate_best(render=False, num_episodes=10)\n",
    "\n",
    "success_rate = sum(r['reached_goal'] for r in neat_results) / len(neat_results)\n",
    "avg_steps = np.mean([r['steps'] for r in neat_results])\n",
    "avg_reward = np.mean([r['reward'] for r in neat_results])\n",
    "\n",
    "print(f\"\\nNEAT Evaluation Results:\")\n",
    "print(f\"  Success Rate: {success_rate:.1%}\")\n",
    "print(f\"  Avg Steps: {avg_steps:.1f}\")\n",
    "print(f\"  Avg Reward: {avg_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train DQN Agent\n",
    "\n",
    "Training the Deep Q-Network (DQN) agent."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Train DQN Agent\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING DQN AGENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "env_dqn = MazeEnv()\n",
    "dqn_solver = DQNMazeSolver(env_dqn, log_dir='../logs/dqn')\n",
    "\n",
    "print(f\"\\nUsing device: {dqn_solver.device}\")\n",
    "print(\"This will take approximately 30-45 minutes on CPU\\n\")\n",
    "\n",
    "dqn_solver.train(num_episodes=500, verbose=True)\n",
    "\n",
    "print(\"\\nâœ… DQN training complete!\")\n",
    "print(f\"Best reward: {dqn_solver.best_reward:.2f}\")\n",
    "\n",
    "dqn_solver.visualize_training()\n",
    "\n",
    "print(\"\\nEvaluating trained DQN agent...\")\n",
    "dqn_results = dqn_solver.evaluate(num_episodes=10, render=False)\n",
    "\n",
    "dqn_success_rate = sum(r['reached_goal'] for r in dqn_results) / len(dqn_results)\n",
    "dqn_avg_steps = np.mean([r['steps'] for r in dqn_results])\n",
    "dqn_avg_reward = np.mean([r['reward'] for r in dqn_results])\n",
    "\n",
    "print(f\"\\nDQN Evaluation Results:\")\n",
    "print(f\"  Success Rate: {dqn_success_rate:.1%}\")\n",
    "print(f\"  Avg Steps: {dqn_avg_steps:.1f}\")\n",
    "print(f\"  Avg Reward: {dqn_avg_reward:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Compare Performance\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "comparison_data = {\n",
    "    'Metric': ['Success Rate', 'Avg Steps', 'Avg Reward', 'Training Time'],\n",
    "    'NEAT': [f\"{success_rate:.1%}\", f\"{avg_steps:.1f}\", f\"{avg_reward:.2f}\", \"~30 min\"],\n",
    "    'DQN': [f\"{dqn_success_rate:.1%}\", f\"{dqn_avg_steps:.1f}\", f\"{dqn_avg_reward:.2f}\", \"~45 min\"]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\", df_comparison.to_string(index=False))\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Success Rate\n",
    "ax = axes[0]\n",
    "methods = ['NEAT', 'DQN']\n",
    "success_rates = [success_rate, dqn_success_rate]\n",
    "bars = ax.bar(methods, success_rates, color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "ax.set_ylabel('Success Rate')\n",
    "ax.set_title('Success Rate Comparison', fontweight='bold')\n",
    "ax.set_ylim(0, 1.1)\n",
    "for bar, rate in zip(bars, success_rates):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., rate, f'{rate:.1%}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Average Steps\n",
    "ax = axes[1]\n",
    "steps = [avg_steps, dqn_avg_steps]\n",
    "bars = ax.bar(methods, steps, color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "ax.set_ylabel('Average Steps')\n",
    "ax.set_title('Efficiency Comparison', fontweight='bold')\n",
    "for bar, step in zip(bars, steps):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., step, f'{step:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Average Reward\n",
    "ax = axes[2]\n",
    "rewards = [avg_reward, dqn_avg_reward]\n",
    "bars = ax.bar(methods, rewards, color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "ax.set_ylabel('Average Reward')\n",
    "ax.set_title('Reward Comparison', fontweight='bold')\n",
    "for bar, reward in zip(bars, rewards):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., reward, f'{reward:.1f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Visualize Decision Making\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DECISION MAKING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "visualizer = TrainingVisualizer(\n",
    "    neat_log_dir='../logs/neat',\n",
    "    dqn_log_dir='../logs/dqn'\n",
    ")\n",
    "\n",
    "print(\"\\nGenerating comparison dashboard...\")\n",
    "visualizer.create_comparison_dashboard()\n",
    "\n",
    "print(\"Generating decision boundary visualization...\")\n",
    "visualizer.visualize_decision_boundaries()\n",
    "\n",
    "print(\"Creating live comparison visualization...\")\n",
    "visualizer.create_live_comparison()\n",
    "\n",
    "print(\"\\nâœ… All visualizations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Robustness Testing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Robustness Testing\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ROBUSTNESS TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_suite = RobustnessTestSuite(\n",
    "    neat_model_path='../logs/neat/best_genome_gen_50.pkl',\n",
    "    dqn_model_path='../logs/dqn/best_model.pth',\n",
    "    neat_config_path='../neuroevolution/config-neat.txt'\n",
    ")\n",
    "\n",
    "print(\"\\n[Test 1/3] Noise Sensitivity Analysis...\")\n",
    "noise_results = test_suite.test_noise_sensitivity(\n",
    "    noise_levels=[0.0, 0.05, 0.1, 0.15, 0.2, 0.3]\n",
    ")\n",
    "\n",
    "print(\"\\n[Test 2/3] Generalization Testing...\")\n",
    "generalization_results = test_suite.test_generalization(num_test_mazes=10)\n",
    "\n",
    "print(\"\\n[Test 3/3] Failure Mode Analysis...\")\n",
    "failure_results = test_suite.test_failure_modes()\n",
    "\n",
    "print(\"\\n[Computing Overall Scores...]\")\n",
    "robustness_scores = test_suite.compute_robustness_score()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ROBUSTNESS SCORES SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for agent in ['neat', 'dqn']:\n",
    "    print(f\"\\n{agent.upper()}:\")\n",
    "    for metric, score in robustness_scores[agent].items():\n",
    "        print(f\"  {metric.replace('_', ' ').title()}: {score:.2f}/100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Conclusions\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NOTEBOOK COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nðŸ“Š All results saved to respective log directories\")\n",
    "print(\"ðŸ“ˆ Visualizations saved to analysis/ directory\")\n",
    "print(\"ðŸŽ¯ Models saved and ready for deployment\")\n",
    "print(\"\\nThank you for exploring NEAT vs DQN maze navigation!\")\n",
    "print(\"For questions or contributions, visit:\")\n",
    "print(\"https://github.com/yourusername/maze-nav-project\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
